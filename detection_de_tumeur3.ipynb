{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Importation des bibliothèques\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from zipfile import ZipFile\n",
        "from google.colab import files\n",
        "\n",
        "# 2. Configuration Kaggle\n",
        "uploaded = files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d navoneel/brain-mri-images-for-brain-tumor-detection\n",
        "with ZipFile(\"brain-mri-images-for-brain-tumor-detection.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/brain_tumor_data\")\n",
        "\n",
        "# 3. Définition des chemins\n",
        "base_dir = '/content/brain_tumor_data/brain_tumor_dataset/'\n",
        "yes_dir = os.path.join(base_dir, 'yes')\n",
        "no_dir = os.path.join(base_dir, 'no')\n",
        "\n",
        "if not os.path.exists(yes_dir) or not os.path.exists(no_dir):\n",
        "    raise FileNotFoundError(\"Répertoire des images manquant.\")\n",
        "\n",
        "num_yes = len(os.listdir(yes_dir))\n",
        "num_no = len(os.listdir(no_dir))\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=['Tumeur', 'Pas de tumeur'], y=[num_yes, num_no])\n",
        "plt.title('Distribution des Classes')\n",
        "plt.ylabel('Nombre d\\'Images')\n",
        "plt.show()\n",
        "\n",
        "# 4. Préparation des données\n",
        "img_width, img_height = 224, 224\n",
        "data = [{'image_path': os.path.join(folder, file), 'label': label}\n",
        "        for label, folder in [('yes', yes_dir), ('no', no_dir)]\n",
        "        for file in os.listdir(folder)]\n",
        "df = pd.DataFrame(data)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "batch_size = 29\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='grayscale',\n",
        "    workers=4\n",
        ")\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='grayscale',\n",
        "    shuffle=False,\n",
        "    workers=4\n",
        ")\n",
        "\n",
        "y_train = train_df['label'].map({'yes': 1, 'no': 0}).values\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# 5. Affichage des images\n",
        "def show_samples(class_name, num_samples=3):\n",
        "    folder = yes_dir if class_name == 'yes' else no_dir\n",
        "    images = os.listdir(folder)[:num_samples]\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i, image_name in enumerate(images):\n",
        "        img_path = os.path.join(folder, image_name)\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(f\"Classe : {class_name}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_samples('yes')\n",
        "show_samples('no')\n",
        "\n",
        "# 6. Définition du modèle\n",
        "def create_model_head():\n",
        "    model = Sequential([\n",
        "        Input(shape=(img_width, img_height, 1)),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = create_model_head()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 7. Entraînement\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=2, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/best_model.keras', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=20,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(test_generator),\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "# 8. Évaluation\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Précision de Test : {test_acc*100:.2f}%\")\n",
        "\n",
        "y_pred = (model.predict(test_generator, verbose=0) > 0.5).astype(int)\n",
        "y_true = test_df['label'].map({'yes': 1, 'no': 0}).values\n",
        "\n",
        "print(\"\\nRapport de Classification :\")\n",
        "print(classification_report(y_true, y_pred, target_names=['No', 'Yes']))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "plt.xlabel('Prédit')\n",
        "plt.ylabel('Vrai')\n",
        "plt.title('Matrice de Confusion')\n",
        "plt.show()\n",
        "\n",
        "# 9. Historique\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Entraînement')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.title('Précision')\n",
        "plt.xlabel('Époque')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Entraînement')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.title('Perte')\n",
        "plt.xlabel('Époque')\n",
        "plt.ylabel('Valeur')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M0ILFc5uZZgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}